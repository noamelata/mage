{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e0da26f2-7eb6-40e2-8ec6-d98308b627f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import torch\n",
    "from mnist import *\n",
    "from ed import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "d004a4eb-4bd2-4802-a50f-47dd8facaebb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[3, 2, 1, 0]"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(range(4-1,-1,-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "a71bd3b2-8ced-450a-b116-7fd66ac8bcee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([9, 8, 0, 4, 6, 9, 4, 2, 3, 5, 9, 4, 3, 2])"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idx = torch.ones([10]).multinomial(num_samples=14, replacement=True)\n",
    "idx\n",
    "torch.eye(src_shape[0])[np.random.choice(src_shape[0], W.shape[0])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "d5f31743-f659-4fdf-99ca-e4b091aca5ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10, 784])"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.linops[0].weight.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e092ef15-d8f7-4c01-a526-8a639591d2a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Namespace(act='relu', arch='fc', aug_lr=0.001, augment=True, batch_size=16, cont=False, cont_src='', cosine=True, dataset='mnist', dir='TMP', epoch_scale=1, epochs=20000, epsilon=1e-05, finite_diff=False, hybrid=False, layers=0, lr=0.1, momentum=0.9, name='', nesterov=True, no_cuda=False, normalize_v=True, per_batch=False, print_freq_test=20, print_freq_train=100, save_model=False, seed=1, sigma=1.25, single=False, skips=True, start_epoch=0, strides=1, tD=False, tW=False, weight_decay=0.0005, widening=2)\n",
      "1.25\n",
      "==> Preparing data..\n",
      "last_ch: 784, ch_out: 10 \n"
     ]
    }
   ],
   "source": [
    "args = parse_txt(\"--arch fc --layers 0 --batch 16\")\n",
    "print(args)\n",
    "model, dl_train, dl_val, device, aname, save_path = get_model(args)\n",
    "\n",
    "optimizer = torch.optim.SGD(model.parameters(), args.lr,\n",
    "                            momentum=args.momentum, nesterov=args.nesterov, weight_decay=args.weight_decay)\n",
    "\n",
    "scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, (len(dl_train))*args.epochs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "1464efbe-a618-49f7-ab3d-4c4a5bf8823b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.0000e+00,  0.0000e+00,  5.9605e-08],\n",
       "        [ 1.1921e-07,  0.0000e+00,  1.1921e-07],\n",
       "        [ 5.9605e-08,  4.7684e-07,  2.3842e-07],\n",
       "        [ 0.0000e+00, -1.1921e-07,  0.0000e+00],\n",
       "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
       "        [-5.9605e-08, -5.9605e-08,  0.0000e+00],\n",
       "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
       "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
       "        [ 0.0000e+00, -1.1921e-07,  1.1921e-07],\n",
       "        [ 0.0000e+00, -2.3842e-07,  0.0000e+00]])"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X  = torch.randn([4,10])\n",
    "Y  = torch.randn([4,3])\n",
    "\n",
    "M1 = torch.matmul(X.unsqueeze(2),Y.unsqueeze(1)).sum(0)\n",
    "M2 = torch.matmul(X.permute(1,0),Y)\n",
    "\n",
    "M1-M2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "59b52deb-5979-4bc5-8554-ad6bcedd4663",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0., 1., 1., 1., 1., 0., 1., 0., 0.],\n",
       "        [0., 1., 0., 1., 0., 1., 0., 0., 1., 1.],\n",
       "        [0., 0., 1., 1., 0., 1., 0., 1., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 1., 1., 1., 1.]])"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(X >= 0).to(torch.float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1123a8f7-0789-4e9e-844e-f8a38090eba0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def L2_np(x):\n",
    "    return x.norm().cpu().numpy()**2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "ec4ec56c-351e-4e90-9791-60260b5563cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 10])"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X =torch.autograd.Variable(torch.randn([4,10]), requires_grad = True)\n",
    "Y = torch.randint(10,[4])\n",
    "L = F.cross_entropy(X, Y, reduction  = 'mean')\n",
    "L.backward()\n",
    "X.grad.shape\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a4d5adcf-e096-495f-acfa-f590cca40f1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 0\n"
     ]
    }
   ],
   "source": [
    "\"\"\"Train for one epoch on the training set\"\"\"\n",
    "# switch to train mode\n",
    "epoch = 0\n",
    "model.train()\n",
    "print('\\nEpoch: %d' % epoch)\n",
    "train_loss = 0\n",
    "total = 0\n",
    "correct = 0\n",
    "epsilon = 1e-5\n",
    "hybrid = True\n",
    "\n",
    "optimizer.zero_grad()\n",
    "\n",
    "for i, (input, target) in enumerate(dl_train):\n",
    "\n",
    "    batch_size = input.shape[0]\n",
    "\n",
    "\n",
    "    input = input.to(device)\n",
    "    target = target.to(device)\n",
    "\n",
    "    x1, x2, V = model.grad_v(input, hybrid = hybrid, epsilon = epsilon)\n",
    "\n",
    "    loss1 =F.cross_entropy(x1, target, reduction  = 'none')\n",
    "    loss2 =F.cross_entropy(x2, target, reduction  = 'none')    \n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dc02fde0-3e6f-464e-b552-45fec189709c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for linop in model.linops:\n",
    "    linop.weight.grad = torch.zeros_like(linop.weight)\n",
    "    linop.bias.grad = torch.zeros_like(linop.bias)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e0270f1a-6a1c-454f-a6be-0b8cb1fca074",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "for b in range(batch_size):\n",
    "\n",
    "    v_b_norm = np.sqrt(np.sum([ L2_np(_vw[b,:,:]) + L2_np(_vb)  for _vw,_vb in V.values()]))\n",
    "    dF = (loss2[b]-loss1[b])/(v_b_norm*epsilon)\n",
    "    for i,(vw,vb) in V.items():\n",
    "        linop = model.linops[i]\n",
    "        linop.weight.grad += dF*vw[b]\n",
    "        linop.bias.grad += dF*vb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1ded4433-6fc6-401f-bedb-a9d106f54837",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer.step()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4dd055fb-9fce-4e81-a2fc-26e279b7b59f",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'V' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_18952/771911096.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mv_b_flat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0m_v\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0m_v\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mV\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'V' is not defined"
     ]
    }
   ],
   "source": [
    "v_b_flat = torch.cat([_v[0].view(-1) for _v in V.values()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f7fd82d0-8a77-400e-9295-4d3d1e1aec33",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5488])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v_b_flat.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "99616115-7367-48eb-bf0c-e1f9828a95e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "def train_v(train_loader, model, args, optimizer, scheduler, epoch, device, writer=None,epsilon = 1e-5, hybrid = False):\n",
    "    \"\"\"Train for one epoch on the training set\"\"\"\n",
    "    # switch to train mode\n",
    "    \n",
    "    model.train()\n",
    "    print('\\nEpoch: %d' % epoch)\n",
    "    train_loss = 0\n",
    "    total = 0\n",
    "    correct = 0\n",
    "    \n",
    "    \n",
    "    for i, (input, target) in tqdm(enumerate(train_loader), total = len(train_loader)):\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        batch_size = input.shape[0]\n",
    "\n",
    "        \n",
    "        input = input.to(device)\n",
    "        target = target.to(device)\n",
    "\n",
    "        x1, x2, V = model.grad_v(input, hybrid = hybrid,  epsilon = epsilon)\n",
    "        \n",
    "        \n",
    "        \n",
    "        for linop in model.linops:\n",
    "            linop.weight.grad = torch.zeros_like(linop.weight)\n",
    "            linop.bias.grad = torch.zeros_like(linop.bias)\n",
    "            \n",
    "        if hybrid:\n",
    "            loss1 =F.cross_entropy(x1, target, reduction  = 'none')\n",
    "            loss2 =F.cross_entropy(x2, target, reduction  = 'none')\n",
    "\n",
    "            for b in range(batch_size):\n",
    "                v_b_norm = np.sqrt(np.sum([ L2_np(_vw[b]) + L2_np(_vb)  for _vw,_vb in V.values()]))\n",
    "                dF = (loss2[b]-loss1[b])/(v_b_norm*epsilon)\n",
    "                for i,(vw,vb) in V.items():\n",
    "                    linop = model.linops[i]\n",
    "                    linop.weight.grad += dF*vw[b]\n",
    "                    linop.bias.grad += dF*vb\n",
    "                    \n",
    "            loss = loss1.mean()\n",
    "        else:\n",
    "            loss1 =F.cross_entropy(x1, target, reduction  = 'mean')\n",
    "            loss2 =F.cross_entropy(x2, target, reduction  = 'mean')\n",
    "            \n",
    "            v_norm = np.sqrt(np.sum([ L2_np(_vw) + L2_np(_vb)  for _vw,_vb in V.values()]))\n",
    "            dF = (loss2-loss1)/(v_norm*epsilon)\n",
    "            for i,(vw,vb) in V.items():\n",
    "                linop = model.linops[i]\n",
    "                linop.weight.grad += dF*vw\n",
    "                linop.bias.grad += dF*vb\n",
    "                \n",
    "            loss = loss1\n",
    "\n",
    "\n",
    "        pred = x1.argmax(dim=1, keepdim=True) # get the index of the max log-probability\n",
    "        correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "\n",
    "        train_loss += loss.item()\n",
    "\n",
    "        total += input.size(0)\n",
    "        optimizer.step()\n",
    "        if args.cosine:\n",
    "            scheduler.step()\n",
    "\n",
    "\n",
    "    train_acc = (100. * correct / len(train_loader.dataset))\n",
    "    train_loss = train_loss/(i+1)\n",
    "    if writer is not None:\n",
    "        writer.add_scalar('train/loss', train_loss, epoch)\n",
    "        writer.add_scalar('train/acc', train_acc, epoch)\n",
    "\n",
    "\n",
    "    return train_loss, train_acc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b613e635-0fd2-4495-b3bf-d5e3e7353f40",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1875/1875 [00:20<00:00, 92.94it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(1078.9549351334572, 13.476666666666667)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "train_v(dl_train, model, args, optimizer, scheduler, 0, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "157c0db4-7b99-43b3-b8ba-952a47a28742",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'3E-5'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loglr = round(np.log(args.lr)/np.log(10))\n",
    "lead = round(args.lr / (10**loglr))\n",
    "\n",
    "lr = f\"{lead}E{loglr}\"\n",
    "lr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06e5979f-e24f-4b71-8bb3-0ce183c3f20d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
